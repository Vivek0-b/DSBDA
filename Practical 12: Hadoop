Hadoop instructions
1. su - Hadoop
2. Files ke other locations, computer mein search karo hadoop likh ke
3. Hadoop ke hadoop folder mein data.txt
banana hai nano se
4. Start sh
5. Ifconfig se ip address copy karo aur uske aage 9870 add karo
6. Hadoop ka page khulega, utilties -> browse file system
7. Admin waali link mein input.txt aur folder directory ka naam apna waala de
8. Javac classpath se com javatpoint mein teeno java codes ka class files banta hai

code to run in terminal 
java -version
su - hadoop
cd hadoop
hadoop version
nano data1.txt
put following text into data1.txt
   	 HDFS is a storage unit of Hadoop
   	 MapReduce is a processing tool of Hadoop
    press control + s then control x

start-all.sh
hdfs dfs -mkdir /test_wc
hdfs dfs -put admin:///home/hadoop/hadoop/data1.txt /test_wc
Ifconfig
  put following URL in firefox
  Ip address followed by :9870
  go to utilities
  browse the file system
  type /test_wc
nano WC_Mapper.java
nano WC_Reducer.java
Nano WC_Runner.java
javac -classpath "$(hadoop classpath)" -d . WC_Mapper.java WC_Reducer.java WC_Runner.java
jar -cvf wordcount.jar com
hadoop jar /home/hadoop/hadoop/wordcount.jar com.javatpoint.WC_Runner /test_wc/data1.txt /r_output
hdfs dfs -cat /r_output/part-00000


















WC_Mapper.java
  package com.javatpoint;  
      
    import java.io.IOException;    
    import java.util.StringTokenizer;    
    import org.apache.hadoop.io.IntWritable;    
    import org.apache.hadoop.io.LongWritable;    
    import org.apache.hadoop.io.Text;    
    import org.apache.hadoop.mapred.MapReduceBase;    
    import org.apache.hadoop.mapred.Mapper;    
    import org.apache.hadoop.mapred.OutputCollector;    
    import org.apache.hadoop.mapred.Reporter;    
    public class WC_Mapper extends MapReduceBase implements Mapper<LongWritable,Text,Text,IntWritable>{    
        private final static IntWritable one = new IntWritable(1);    
        private Text word = new Text();    
        public void map(LongWritable key, Text value,OutputCollector<Text,IntWritable> output,     
               Reporter reporter) throws IOException{    
            String line = value.toString();    
            StringTokenizer  tokenizer = new StringTokenizer(line);    
            while (tokenizer.hasMoreTokens()){    
                word.set(tokenizer.nextToken());    
                output.collect(word, one);    
            }    
        }    
        
    }  




WC_Reducer.java

    package com.javatpoint;  
        import java.io.IOException;    
        import java.util.Iterator;    
        import org.apache.hadoop.io.IntWritable;    
        import org.apache.hadoop.io.Text;    
        import org.apache.hadoop.mapred.MapReduceBase;    
        import org.apache.hadoop.mapred.OutputCollector;    
        import org.apache.hadoop.mapred.Reducer;    
        import org.apache.hadoop.mapred.Reporter;    
            
        public class WC_Reducer  extends MapReduceBase implements Reducer<Text,IntWritable,Text,IntWritable> {    
        public void reduce(Text key, Iterator<IntWritable> values,OutputCollector<Text,IntWritable> output,    
         Reporter reporter) throws IOException {    
        int sum=0;    
        while (values.hasNext()) {    
        sum+=values.next().get();    
        }    
        output.collect(key,new IntWritable(sum));    
        }    
        }  


WC_Runner.java

  package com.javatpoint;  
      
        import java.io.IOException;    
        import org.apache.hadoop.fs.Path;    
        import org.apache.hadoop.io.IntWritable;    
        import org.apache.hadoop.io.Text;    
        import org.apache.hadoop.mapred.FileInputFormat;    
        import org.apache.hadoop.mapred.FileOutputFormat;    
        import org.apache.hadoop.mapred.JobClient;    
        import org.apache.hadoop.mapred.JobConf;    
        import org.apache.hadoop.mapred.TextInputFormat;    
        import org.apache.hadoop.mapred.TextOutputFormat;    
        public class WC_Runner {    
            public static void main(String[] args) throws IOException{    
                JobConf conf = new JobConf(WC_Runner.class);    
                conf.setJobName("WordCount");    
                conf.setOutputKeyClass(Text.class);    
                conf.setOutputValueClass(IntWritable.class);            
                conf.setMapperClass(WC_Mapper.class);    
                conf.setCombinerClass(WC_Reducer.class);    
                conf.setReducerClass(WC_Reducer.class);         
                conf.setInputFormat(TextInputFormat.class);    
                conf.setOutputFormat(TextOutputFormat.class);           
                FileInputFormat.setInputPaths(conf,new Path(args[0]));    
                FileOutputFormat.setOutputPath(conf,new Path(args[1]));     
                JobClient.runJob(conf);    
            }    
        }    
